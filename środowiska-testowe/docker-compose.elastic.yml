services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.2.4
    container_name: elasticsearch
    hostname: elasticsearch
    environment:
      - TZ=Europe/Warsaw
      - discovery.type=single-node
      - cluster.name=sbom-cluster
      - node.name=es01

      # PoC: wyłączamy security, żeby Jenkins mógł wrzucać eventy przez HTTP bez certów i userów
      - xpack.security.enabled=false

      # sensowna pamięć dla kontenera (dopasuj do hosta)
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    ports:
      - "9200:9200"   # Elasticsearch HTTP
      - "9300:9300"   # transport (opcjonalnie)
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -fsS http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=2s | grep -q '\"status\"'"]
      interval: 20s
      timeout: 10s
      retries: 30
      start_period: 60s
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:9.2.4
    container_name: kibana
    hostname: kibana
    environment:
      - TZ=Europe/Warsaw
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - xpack.security.enabled=false
    ports:
      - "5601:5601"   # Kibana UI
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -fsS http://localhost:5601/api/status | grep -q '\"level\":\"available\"'"]
      interval: 20s
      timeout: 10s
      retries: 40
      start_period: 120s
    restart: unless-stopped

  # Minimalny „odpowiednik splunk-app”: zakłada pipeline + template pod indeks SBOM
  elastic_setup:
    image: curlimages/curl:8.10.1
    container_name: elastic_setup
    depends_on:
      elasticsearch:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-lc"]
    command: |
      set -e

      echo "Creating index template: sbom-template"
      curl -fsS -X PUT http://elasticsearch:9200/_index_template/sbom-template \
        -H 'Content-Type: application/json' \
        -d '{
          "index_patterns": ["sbom-*"],
          "template": {
            "settings": { "number_of_shards": 1, "number_of_replicas": 0 },
            "mappings": {
              "dynamic": true,
              "properties": {
                "@timestamp": { "type": "date" },
                "app_id":     { "type": "keyword" },
                "app_version":{ "type": "keyword" },
                "vcs_ref":    { "type": "keyword" },
                "owner_team": { "type": "keyword" },
                "type":       { "type": "keyword" },
                "source":     { "type": "keyword" }
              }
            }
          }
        }'

      echo "Creating ingest pipeline: sbom-normalize"
      curl -fsS -X PUT http://elasticsearch:9200/_ingest/pipeline/sbom-normalize \
        -H 'Content-Type: application/json' \
        -d '{
          "description": "Minimal normalization for SBOM events",
          "processors": [
            { "set": { "field": "@timestamp", "value": "{{_ingest.timestamp}}" } }
          ]
        }'

      echo "Done."
    restart: "no"

  jenkins:
    image: jenkins/jenkins:lts-jdk17
    container_name: jenkins
    hostname: jenkins
    user: "0"
    environment:
      - TZ=Europe/Warsaw

      # Najprostszy ingest z Jenkins: POST JSON prosto do indeksu
      # Uwaga: w realu zwykle idziesz w Elastic Agent / Logstash / API keys + TLS,
      # ale tu trzymamy analogię do HEC i prostotę PoC.
      - ELASTIC_INGEST_URL=http://elasticsearch:9200/sbom-events/_doc?pipeline=sbom-normalize
    ports:
      - "8080:8080"   # Jenkins UI
      - "50000:50000" # inbound agents (opcjonalnie)
    volumes:
      - jenkins_home:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
      elastic_setup:
        condition: service_completed_successfully
    restart: unless-stopped

volumes:
  es_data:
  jenkins_home:
